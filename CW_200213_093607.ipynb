{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:05:15.300702Z",
     "start_time": "2020-02-28T20:05:13.287703Z"
    }
   },
   "source": [
    "reset\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append(r'D:\\WorkSpaces\\ClaireRenataGrantFeb2020')\n",
    "sys.path.remove('D:\\\\WorkSpaces\\\\ClaireRenataGrantJuly2020\\\\session notebooks')\n",
    "sys.path.remove('D:\\\\WorkSpaces\\\\ClaireRenataGrantFeb2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:21:38.384592Z",
     "start_time": "2020-05-28T19:21:38.344674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\WorkSpaces\\\\ClaireRenataGrantJuly2020\\\\session notebooks',\n",
       " 'D:\\\\WorkSpaces\\\\ClaireRenataGrantFeb2020',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\python37.zip',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3',\n",
       " '',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\ehsan\\\\.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:21:13.412950Z",
     "start_time": "2020-05-28T19:21:12.827507Z"
    }
   },
   "outputs": [],
   "source": [
    "# the basic modules that are used throught the notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "\n",
    "from scipy import signal\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reloading the funtions each time they are called"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with the magical functions in the below cell we make sure that if we run a function, its last version is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:21:17.873515Z",
     "start_time": "2020-05-28T19:21:17.830628Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing functions and setting the options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:21:11.894206Z",
     "start_time": "2020-05-28T15:21:11.379482Z"
    }
   },
   "outputs": [],
   "source": [
    "#the functions are imported from the folders in the same directory as the notebook\n",
    "\n",
    "from intanRead.IntanRaw_read_data import IntanRaw_read_data\n",
    "\n",
    "from basicFunctions.filters import \\\n",
    "                        butter_bandpass_filter,butter_highpass_filter,butter_lowpass_filter\n",
    "from basicFunctions.firingRate import firingRate\n",
    "from basicFunctions.temporalPlot import temporalPlot\n",
    "from basicFunctions.crossCorrelogram import crossCorrelogram\n",
    "\n",
    "from mainFunctions.loadDataFilePath import loadDataFilePath\n",
    "from mainFunctions.readDigitalChannels import readDigitalChannels\n",
    "from mainFunctions.readAnalogChannels import readAnalogChannels\n",
    "from mainFunctions.stimOnsetExtraction import stimOnsetExtraction\n",
    "from mainFunctions.loadSpikesFromPhy import loadSpikesFromPhy\n",
    "from mainFunctions.neuronsInfoExtraction import neuronsInfoExtraction\n",
    "from mainFunctions.pupilSizeReading import pupilSizeReading\n",
    "from mainFunctions.spikeTriggeredAvgPupilSize import spikeTriggeredAvgPupilSize\n",
    "from mainFunctions.neuronVisualResponse import neuronVisualResponse\n",
    "from mainFunctions.tuningCurveAndOSI import tuningCurveAndOSI\n",
    "from mainFunctions.extractLowAndHighArousalTrials import extractLowAndHighArousalTrials\n",
    "from mainFunctions.allTrialsResponses import allTrialsResponses\n",
    "from mainFunctions.responseChangeByAlertness import responseChangeByAlertness\n",
    "from mainFunctions.bestOrienationResponseChangeByAlertness\\\n",
    "                    import bestOrienationResponseChangeByAlertness\n",
    "from mainFunctions.noiseCorrBetweenAlertAndNonAlertTrials\\\n",
    "                    import noiseCorrBetweenAlertAndNonAlertTrials\n",
    "from mainFunctions.powerSpectrumSingleChannel import powerSpectrumSingleChannel\n",
    "from mainFunctions.estimatedL5chnnael import estimatedL5chnnael\n",
    "from mainFunctions.exctractAlertAndNonAlertPeriods import exctractAlertAndNonAlertPeriods\n",
    "from mainFunctions.spectrumCompareAlertNonAlert import spectrumCompareAlertNonAlert\n",
    "from mainFunctions.normalizedBetween_0_and_1 import normalizedBetween_0_and_1\n",
    "from mainFunctions.spontFR_CompareAlertAndNonAlert import spontFR_CompareAlertAndNonAlert\n",
    "from mainFunctions.hilbertTransformedLFP_FrameRateAvg import hilbertTransformedLFP_FrameRateAvg\n",
    "from mainFunctions.motionStillnessPowerCompare import motionStillnessPowerCompare\n",
    "from mainFunctions.powerLFP_FrameAvg import powerLFP_FrameAvg\n",
    "from mainFunctions.stimOffsetExtraction import stimOffsetExtraction\n",
    "from mainFunctions.facemapDataReading import facemapDataReading\n",
    "from mainFunctions.spikeTriggeredAvgFacialMovement import spikeTriggeredAvgFacialMovement\n",
    "from mainFunctions.motionStillnessPowerCompareGammaAndLowFreq\\\n",
    "                        import motionStillnessPowerCompareGammaAndLowFreq\n",
    "from mainFunctions.spikeTriggeredFR import spikeTriggeredFR\n",
    "from mainFunctions.spikeTriggeredFR_alertNonAlert import spikeTriggeredFR_alertNonAlert\n",
    "\n",
    "\n",
    "darkMode = True\n",
    "if darkMode:\n",
    "    plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:26:21.202645Z",
     "start_time": "2020-05-28T15:23:13.572784Z"
    }
   },
   "outputs": [],
   "source": [
    "dataDriveLabel = 'renatalab' # the label of the shared network directory for the data\n",
    "dataDirectory = 'Ehsan-temp\\Claire-Ehsan_Share' # the address inside the directory that has the data\n",
    "\n",
    "# because the shared directory is mapped with different names on different computer, here we extract the\n",
    "# the drive letter of the shared dirctory of the data\n",
    "import win32api\n",
    "\n",
    "drives = win32api.GetLogicalDriveStrings()\n",
    "drives = drives.split('\\000')[:-1]\n",
    "\n",
    "for driveLetter in drives:\n",
    "    try:\n",
    "        if win32api.GetVolumeInformation(driveLetter)[0] == dataDriveLabel:\n",
    "            dataDriveLetter = driveLetter\n",
    "            break\n",
    "    except:\n",
    "        print(driveLetter)\n",
    "\n",
    "# select the re-referenced high-pass filtered data file, we use this to extract the folder which is \n",
    "# supposed to contain oll the related data files for this session, and this file itself is used to \n",
    "# extract the spike wave-shapes\n",
    "dataFileAdd, dataFileBaseFolder, infoFileAdd = loadDataFilePath\\\n",
    "                            (dataDriveLetter + dataDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the info file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:52:12.638941Z",
     "start_time": "2020-04-22T12:52:12.526031Z"
    }
   },
   "outputs": [],
   "source": [
    "# here we read the intan info file and load some basic variables\n",
    "\n",
    "infoResult = IntanRaw_read_data(infoFileAdd)\n",
    "channelsNo = len(infoResult['amplifier_channels'])\n",
    "ADC_channelsNo = len(infoResult['board_adc_channels'])\n",
    "fs = int(infoResult['frequency_parameters']['board_dig_in_sample_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the digital data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:52:21.948632Z",
     "start_time": "2020-04-22T12:52:16.025914Z"
    }
   },
   "outputs": [],
   "source": [
    "# here we read the data from the digital port of the Intan and extracting the stim IDs, the sample that \n",
    "# the first tag for the stim happens as well as the sample that the tag for the last stim hppens. As the\n",
    "# last output we get an estimation of the stim onset times based on the digital tags\n",
    "\n",
    "stimID, firstBeforeStimTagSampleNo , lastStimTagSampleNo, \\\n",
    "        stimOnset_DigitalTag_afterStimOnFlip = readDigitalChannels(dataFileBaseFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the analog data file to extract raw photoDiodeSignal and raw camerastrob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:52:42.144312Z",
     "start_time": "2020-04-22T12:52:28.421472Z"
    }
   },
   "outputs": [],
   "source": [
    "photoDiodeSignal, cameraStrobe, wheelSensorSignal = readAnalogChannels(dataFileBaseFolder,ADC_channelsNo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting frame start samples and reading facemap data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "background: for each saved frame from camera one step pulse is sent to the Intan and is saved along with other signals. We have to determine what is the sample number (according to the Intan sampling) for the starting of each frame. \n",
    "Here in 'facemapDataReading' function we do two things: \n",
    "1 - we extract the starting samples (according to intan sampling) for each saved frame, this is the first output of the function\n",
    "2 - we load the pupil size and facial movement from the facemap (second and third outputs of this function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:53:40.657515Z",
     "start_time": "2020-04-22T12:52:46.086582Z"
    }
   },
   "outputs": [],
   "source": [
    "framesStartSample, pupilSmoothArea, motion = \\\n",
    "                                facemapDataReading(cameraStrobe,dataFileBaseFolder,darkMode = darkMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stimOnset based on the photoDiode Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:54:17.102603Z",
     "start_time": "2020-04-22T12:53:46.295878Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stimOnsetSample = stimOnsetExtraction(photoDiodeSignal,firstBeforeStimTagSampleNo, lastStimTagSampleNo,\\\n",
    "                            stimOnset_DigitalTag_afterStimOnFlip,\\\n",
    "                                      fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting the stim offset samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:54:56.261782Z",
     "start_time": "2020-04-22T12:54:25.269432Z"
    }
   },
   "outputs": [],
   "source": [
    "stimOffsetSample = stimOffsetExtraction(photoDiodeSignal,firstBeforeStimTagSampleNo, lastStimTagSampleNo,\\\n",
    "                            stimOnset_DigitalTag_afterStimOnFlip,\\\n",
    "                                      fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the sorting results from KiloSort-Phy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ctl+s in Phy first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:59:09.608824Z",
     "start_time": "2020-04-22T12:55:02.279170Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spikesSample, spikeClusters, SUA_clusters, MUA_clusters = loadSpikesFromPhy(dataFileBaseFolder)\n",
    "spikeTime = spikesSample/fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the spike wave-shapes, spont FRs and the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:00:04.882404Z",
     "start_time": "2020-04-22T12:59:16.234632Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spontFRs, spikeWidthAll, clusterChannel, spikeShapesFiltered, spikeClustersToPlot, recordingDurInMS = \\\n",
    "    neuronsInfoExtraction(dataFileAdd, spikesSample, spikeClusters, SUA_clusters, MUA_clusters,\\\n",
    "                          firstBeforeStimTagSampleNo,\\\n",
    "                          fs, spikeTypes = 'SUA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spike-triggered Average of pupil size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:02:20.816854Z",
     "start_time": "2020-04-22T13:01:07.547630Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allSpikeTriggeredPupil = spikeTriggeredAvgPupilSize(framesStartSample,\\\n",
    "                                 pupilSmoothArea, spikeClustersToPlot, spikeTime, spikeClusters,\\\n",
    "                                                    spontFRs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spike-triggered Average of facial motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:27:34.400005Z",
     "start_time": "2020-04-30T19:26:10.345182Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allSpikeTriggeredFacialMovement = spikeTriggeredAvgFacialMovement(framesStartSample,\\\n",
    "                                 motion, spikeClustersToPlot, spikeTime, spikeClusters, spontFRs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Movement, Pupil and Alertness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining a criteria for alertness based on the distribution of pupil sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:11:14.995248Z",
     "start_time": "2020-04-22T13:11:14.845644Z"
    }
   },
   "outputs": [],
   "source": [
    "# alertness threshold: first estimate the maximum of the pupil area --> 90 percent of the pupil area distribution\n",
    "# and define the alertness as the half of this value, and check how much time animal has been alert\n",
    "plt.hist(pupilSmoothArea)\n",
    "# plt.axvline(0.3*np.max(pupilSmoothArea))\n",
    "alertnessThreshold = np.percentile(pupilSmoothArea,90)*0.5\n",
    "plt.axvline(alertnessThreshold)\n",
    "\n",
    "print('the proportion time that animal has been alert:',\\\n",
    "      len(pupilSmoothArea[pupilSmoothArea>alertnessThreshold])/len(pupilSmoothArea))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smoothing the motion signal by calculating the average energy across moving windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:11:20.926804Z",
     "start_time": "2020-04-22T13:11:20.709359Z"
    }
   },
   "outputs": [],
   "source": [
    "cameraAvgFrameRate = 30\n",
    "\n",
    "# width of averging window\n",
    "avgWindowWidth = 1\n",
    "avgWindowWidthFrameNo = int(avgWindowWidth * cameraAvgFrameRate)\n",
    "\n",
    "# convolving the motion energy with a rectangular window to get moving average\n",
    "movingWindowEnergy = np.convolve(motion**2,np.ones(avgWindowWidthFrameNo),'same')/avgWindowWidthFrameNo\n",
    "\n",
    "# movingWindowEnergy = np.concatenate((np.zeros(int(avgWindowWidthFrameNo/2))\\\n",
    "#                                      ,movingWindowEnergy))[:len(motion)]\n",
    "\n",
    "# comparing the original motion signal and smoothed motion energy\n",
    "startTime = 0\n",
    "endTime = 100\n",
    "temporalPlot(motion/max(motion),startTime,endTime,30,figuresize=(10,4),lineColor='c')\n",
    "# plt.figure()\n",
    "temporalPlot(movingWindowEnergy/max(movingWindowEnergy),startTime,endTime,30,linewidth=4,lineColor='y')\n",
    "\n",
    "plt.legend(['motion','smoothed energy'])\n",
    "\n",
    "# plt.figure()\n",
    "# temporalPlot(pupilSmoothArea/max(pupilSmoothArea),startTime,endTime,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparing the pupil signal, facial movement and locomotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:12:01.944098Z",
     "start_time": "2020-04-22T13:11:25.709287Z"
    }
   },
   "outputs": [],
   "source": [
    "startTime = 0\n",
    "endTime = 500\n",
    "\n",
    "temporalPlot(pupilSmoothArea/max(pupilSmoothArea),startTime,endTime,30,figuresize=(10,6),lineColor='grey')\n",
    "\n",
    "\n",
    "temporalPlot(movingWindowEnergy/max(movingWindowEnergy),startTime,endTime,30)\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "\n",
    "firstCapturedFrame_Sample = framesStartSample[0]\n",
    "\n",
    "temporalPlot(wheelSensorSignal[firstCapturedFrame_Sample:]/max(wheelSensorSignal),startTime,\\\n",
    "             endTime,fs,lineColor='y')\n",
    "\n",
    "plt.legend(['pupil area','facial movement','locomotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visual responsiveness of neurons"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we plot the raster plot of each neuron in response to each orientation\n",
    "We also calculate the average firing rate of the neuron in response to each orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T20:20:31.523506Z",
     "start_time": "2020-04-29T20:17:12.594549Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allClustersResponsiveness = []\n",
    "allClustersBaselineCorrectedResponse = []\n",
    "allClustersMaxFR_response = []\n",
    "allClustersFR_responsePattern = []\n",
    "\n",
    "for clusterNo in spikeClustersToPlot[:]:\n",
    "    \n",
    "    # extract the time of spikes for the cluster in this loop iteration\n",
    "    clusterSpikeTime = spikeTime[np.where(spikeClusters==clusterNo)].squeeze() \n",
    "    \n",
    "    responsiveness, clusterBaselineCorrectedResponse, clusterMaxResponse, clusterResponsivenessPvals,\\\n",
    "    FR_responsePattern, FR_responseTimePoints = \\\n",
    "        neuronVisualResponse(clusterSpikeTime,clusterNo,stimID,stimOnsetSample, \\\n",
    "                             responseWindowEnd = 3000, darkMode = darkMode);\n",
    "    \n",
    "    allClustersResponsiveness.append(responsiveness)\n",
    "    allClustersBaselineCorrectedResponse.append(clusterBaselineCorrectedResponse)\n",
    "    allClustersMaxFR_response.append(clusterMaxResponse)\n",
    "    allClustersFR_responsePattern.append(FR_responsePattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning curve and Orienation Selectivity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T20:20:58.128336Z",
     "start_time": "2020-04-29T20:20:56.952234Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allOSI = []\n",
    "# allOSI_max = []\n",
    "for clusterCounter in range(len(spikeClustersToPlot)):\n",
    "    if allClustersResponsiveness[clusterCounter]:\n",
    "        allOSI.append(tuningCurveAndOSI(allClustersBaselineCorrectedResponse[clusterCounter],\\\n",
    "                                       spikeClustersToPlot[clusterCounter]));\n",
    "#     allOSI_max.append(tuningCurveAndOSI(allClustersMaxFR_response[clusterNo]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline and Evoked comparison between alert and non alert trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T20:38:31.018789Z",
     "start_time": "2020-04-29T20:38:29.618531Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting the high and low-arousal level trials based on the smoothed facial movement signal\n",
    "lowArousalStimTrials, highArousalStimTrials = \\\n",
    "            extractLowAndHighArousalTrials(framesStartSample, movingWindowEnergy, stimOnsetSample,\\\n",
    "                timeWindowBeforeStimStart = 500,\\\n",
    "                timeWindowAfterStimStart = 0)\n",
    "\n",
    "allTrialsRelResponse, allTrialsBaseline, allTrialsEvokedResponse\\\n",
    "                    = allTrialsResponses(spikeClusters, spikeTime, stimOnsetSample,\\\n",
    "                        spikeClustersToPlot[np.where(allClustersResponsiveness)])\n",
    "\n",
    "# response change by alertness\n",
    "\n",
    "allClustersNormalizedArousalResponseChange, allPvalArousalResponseDiff = responseChangeByAlertness(\\\n",
    "            spikeClustersToPlot[np.where(allClustersResponsiveness)],\\\n",
    "            allTrialsRelResponse,highArousalStimTrials,lowArousalStimTrials)\n",
    "\n",
    "# Basline change by alertness\n",
    "allClustersNormalizedArousalBaselineChange, allPvalaselineChange = responseChangeByAlertness(\\\n",
    "            spikeClustersToPlot[np.where(allClustersResponsiveness)],\\\n",
    "            allTrialsBaseline,highArousalStimTrials,lowArousalStimTrials,\\\n",
    "            figTitle = 'Baseline Change By Alertness')\n",
    "\n",
    "# Evoked response change in the preferred stim by alertness\n",
    "evokedResponseChangeByArousa, pvalEvokedResponseChange = \\\n",
    "bestOrienationResponseChangeByAlertness(spikeClustersToPlot,allTrialsEvokedResponse,\\\n",
    "    highArousalStimTrials,lowArousalStimTrials,allClustersBaselineCorrectedResponse,\\\n",
    "    allClustersResponsiveness,stimID,figTitle = 'Evoked Response Change By Alertness in Preferred Direction ');\n",
    "\n",
    "# relative response change in the preferred stim by alertness\n",
    "bestDirectionRelResponseChangeByArousal, pvalBestDirectionResponseChange = \\\n",
    "bestOrienationResponseChangeByAlertness(spikeClustersToPlot,allTrialsRelResponse,\\\n",
    "    highArousalStimTrials,lowArousalStimTrials,allClustersBaselineCorrectedResponse,\\\n",
    "    allClustersResponsiveness,stimID,figTitle = 'Relative Response Change By Alertness in Preferred Direction ');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Curve and OSI between Alert and non Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:11:03.162760Z",
     "start_time": "2020-04-29T21:11:00.750246Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allClustersAlertMeanOrientationResponse = []\n",
    "allClustersNonAlertMeanOrientationResponse = []\n",
    "OSI_Alert = []\n",
    "OSI_nonAlert = []\n",
    "for clusterCounter in range(len(np.where(allClustersResponsiveness)[0])):\n",
    "\n",
    "    alertMeanOrientationResponse = []\n",
    "    nonAlertMeanOrientationResponse = []\n",
    "    for orientationCounter in np.unique(stimID):\n",
    "\n",
    "        alertResponseCluster = allTrialsRelResponse[clusterCounter]\\\n",
    "                            [np.intersect1d(np.where(stimID==orientationCounter)[0], highArousalStimTrials)]\n",
    "\n",
    "        nonAlertResponseCluster = allTrialsRelResponse[clusterCounter]\\\n",
    "                            [np.intersect1d(np.where(stimID==orientationCounter)[0], lowArousalStimTrials)]\n",
    "\n",
    "        alertMeanOrientationResponse.append(np.mean(alertResponseCluster))\n",
    "        nonAlertMeanOrientationResponse.append(np.mean(nonAlertResponseCluster))\n",
    "        \n",
    "    allClustersAlertMeanOrientationResponse.append(alertMeanOrientationResponse)\n",
    "    allClustersNonAlertMeanOrientationResponse.append(nonAlertMeanOrientationResponse)\n",
    "#         print(stats.ttest_ind(alertResponseCluster,nonAlertResponseCluster)[1],\\\n",
    "#              np.mean(alertResponseCluster),np.mean(nonAlertResponseCluster))\n",
    "    \n",
    "    OSI_Alert.append(tuningCurveAndOSI(alertMeanOrientationResponse,\\\n",
    "                                       spikeClustersToPlot[clusterCounter]))\n",
    "    OSI_nonAlert.append(tuningCurveAndOSI(nonAlertMeanOrientationResponse,\\\n",
    "                                          spikeClustersToPlot[clusterCounter]))\n",
    "    \n",
    "if len(np.where(allClustersResponsiveness)[0]):\n",
    "    plt.figure()\n",
    "    plt.plot([1,2],np.array([OSI_Alert,OSI_nonAlert]),'o-')\n",
    "    plt.xticks([1,2],(['Alert','nonAlert']),fontsize=12)\n",
    "    plt.title('OSI change with alertness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noise correlation between alert and non-alert trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:12:47.492319Z",
     "start_time": "2020-04-29T21:12:47.364656Z"
    }
   },
   "outputs": [],
   "source": [
    "noiseCorrAlert, noiseCorrNonAlert, pval = noiseCorrBetweenAlertAndNonAlertTrials\\\n",
    "        (allTrialsRelResponse,highArousalStimTrials,lowArousalStimTrials)\n",
    "\n",
    "# print(stats.ttest_ind(noiseCorrAlert,noiseCorrNonAlert)[1],np.mean(noiseCorrAlert)\\\n",
    "#               ,np.mean(noiseCorrNonAlert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### power Spectrum across layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### estimated L5 channel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "based on the Senzai et al., 2018; we are looking at the total power between 500Hz and 5000Hz across the channels, the channel with the highest power is estimated to be at the center of L5\n",
    "\n",
    "Since the 64 channel probe might reach Hippocampus, this needs to be checked in each session so that the result match the experimenters expectation and makes sense. Generally this happens around the channel 30. We don't know if this is a correct criteria for the pups or mutant animals? (should be checked with histology)\n",
    "\n",
    "Also we are getting sensible estimation with re-referenced or the orginial data in different sessions, so it is suggested that both signals are checked and the estimation are compared in each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:07:01.316525Z",
     "start_time": "2020-04-22T13:05:16.891795Z"
    }
   },
   "outputs": [],
   "source": [
    "# the address to the data file (the original reordered or re-referenced recordered)\n",
    "dataFileAddReorderRereferenced = dataFileBaseFolder + '/' + 'amplifierReorderRereferencedMedian.dat'\n",
    "\n",
    "# the estimation of L5 based on the power in 500-5000 Hz band\n",
    "L5channelNo, allChannelsNormHighFreqPower,\\\n",
    "        allChannelsHighFreqPower = estimatedL5chnnael(dataFileAddReorderRereferenced,\\\n",
    "                                                      firstBeforeStimTagSampleNo)\n",
    "\n",
    "# the estimation of the L4 and L2/3 based on the estimated position for L5\n",
    "L4channelNo = L5channelNo - 8\n",
    "L23channelNo = L5channelNo - 15"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataFileAddReorderRereferenced = dataFileBaseFolder + '/' + 'amplifierReorder.dat'\n",
    "L5channelNo, allChannelsNormHighFreqPower,\\\n",
    "        allChannelsHighFreqPower = estimatedL5chnnael(dataFileAddReorderRereferenced,\\\n",
    "                                                      firstBeforeStimTagSampleNo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading low pass filtered data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:07:29.318539Z",
     "start_time": "2020-04-22T13:07:26.836135Z"
    }
   },
   "outputs": [],
   "source": [
    "dataFile = open(dataFileBaseFolder + '/' + 'amplifierReorderRereferencedLowPass.dat' , 'rb')\n",
    "dataArray = np.fromfile(dataFile,dtype='int16')\n",
    "dataFile.close()\n",
    "\n",
    "del dataFile\n",
    "\n",
    "dataMatrixReorderLowPassFiltered = np.reshape(dataArray, (int(dataArray.shape[0]/channelsNo), channelsNo)).T\n",
    "\n",
    "del dataArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### power spectrum across layers during spontaneous activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:07:43.540231Z",
     "start_time": "2020-04-22T13:07:42.379333Z"
    }
   },
   "outputs": [],
   "source": [
    "# the spontaneous activity is recorded at the begining of the session and the varialbe \n",
    "# \"firstBeforeStimTagSampleNo\" that indicate the first visual stimulus is used to extract the last moment\n",
    "# of the spontaneous activity\n",
    "\n",
    "spontEndTime = firstBeforeStimTagSampleNo/fs # in seconds\n",
    "\n",
    "# the reduced sampling rate used to generated low-pass filtered LFP\n",
    "reducedSamplingRate = 2e3\n",
    "\n",
    "# the resolution of power spectrum\n",
    "df = 0.5\n",
    "\n",
    "# extracting the spont activity on L5 channel and conversion to microVolts by multiplying to 0.195\n",
    "inputSignalToFreqAnalysis = dataMatrixReorderLowPassFiltered[L5channelNo]\\\n",
    "                                 [:int(spontEndTime*reducedSamplingRate)]*0.195\n",
    "\n",
    "# power spectrum L5\n",
    "f_powerSpectrum, powerSpectrumL5, estimatedTotalPower = \\\n",
    "            powerSpectrumSingleChannel(inputSignalToFreqAnalysis,reducedSamplingRate\\\n",
    "                                          ,figToShow = True,\\\n",
    "maxFreqToShow = 120, freqRes = df, Normalized = 1, figTitle = 'spectrum in L5 - spont' )\n",
    "\n",
    "print(estimatedTotalPower)\n",
    "\n",
    "# extracting the spont activity on L4 channel and conversion to microVolts by multiplying to 0.195\n",
    "inputSignalToFreqAnalysis = dataMatrixReorderLowPassFiltered[L4channelNo]\\\n",
    "                                 [:int(spontEndTime*reducedSamplingRate)]*0.195\n",
    "# power spectrum L4\n",
    "f, powerSpectrumL4, estimatedTotalPower = \\\n",
    "            powerSpectrumSingleChannel(inputSignalToFreqAnalysis,reducedSamplingRate\\\n",
    "                                          ,figToShow = True,\\\n",
    "maxFreqToShow = 120, freqRes = df, Normalized = 1, figTitle = 'spectrum in L4 - spont' )\n",
    "print(estimatedTotalPower)\n",
    "\n",
    "# extracting the spont activity on L2/3 channel and conversion to microVolts by multiplying to 0.195\n",
    "inputSignalToFreqAnalysis = dataMatrixReorderLowPassFiltered[L23channelNo]\\\n",
    "                                 [:int(spontEndTime*reducedSamplingRate)]*0.195\n",
    "# power spectrum L2/3\n",
    "f, powerSpectrumL23, estimatedTotalPower = \\\n",
    "            powerSpectrumSingleChannel(inputSignalToFreqAnalysis,reducedSamplingRate\\\n",
    "                                          ,figToShow = True,\\\n",
    "maxFreqToShow = 120, freqRes = df, Normalized = 1, figTitle = 'spectrum in L2/3 - spont' )\n",
    "print(estimatedTotalPower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining a criteria for movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:12:18.280745Z",
     "start_time": "2020-04-22T13:12:17.893807Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(movingWindowEnergy)\n",
    "\n",
    "# a fraction of 90% percentile\n",
    "movementThreshold = np.percentile(movingWindowEnergy,90)*0.25\n",
    "plt.axvline(movementThreshold)\n",
    "\n",
    "print('the proportion time that animal has been moving with this criteris: %(number)d%%' %{'number':\\\n",
    "      100*len(movingWindowEnergy[movingWindowEnergy>movementThreshold])/len(movingWindowEnergy)})\n",
    "\n",
    "startTime = 0\n",
    "endTime = 1000\n",
    "temporalPlot(movingWindowEnergy/max(movingWindowEnergy),startTime,endTime,30,figuresize=(15,4))\n",
    "\n",
    "temporalPlot(movementThreshold*np.ones(len(movingWindowEnergy))/max(movingWindowEnergy),\\\n",
    "             startTime,endTime,30)\n",
    "\n",
    "plt.legend(['motion smoothed','movement threshold'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detecting the consecutive periods of movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:12:22.600698Z",
     "start_time": "2020-04-22T13:12:22.557785Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is to extract the epochs of movement and non-movement during spont activity\n",
    "# movement criteria is set based on the movementThreshold calculated above\n",
    "# to consider an epoch for movement or non-movement, it should be at least \"minimumConsistentStateDur\"\n",
    "# seconds long\n",
    "\n",
    "minimumConsistentStateDur = 2\n",
    "\n",
    "alertChoosedEpochsStarts, alertChoosedEpochsEnds, nonAlertChoosedEpochsStarts, \\\n",
    "    nonAlertChoosedEpochsEnds = exctractAlertAndNonAlertPeriods(movingWindowEnergy,framesStartSample,\\\n",
    "                0,spontEndTime, minimumConsistentStateDur = minimumConsistentStateDur,\\\n",
    "                alertnessThreshold = movementThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking the LFP around the time of movement start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:17:43.513019Z",
     "start_time": "2020-03-30T15:17:33.129758Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert\n",
    "\n",
    "windowToShow = 20\n",
    "reducedSamplingRate = 2e3\n",
    "\n",
    "inputSignalToFreqAnalysis = dataMatrixReorderLowPassFiltered[L5channelNo]\n",
    "\n",
    "# lowFreqBand = 1\n",
    "highFreqBand = 150\n",
    "inputSignalToFreqAnalysis = butter_lowpass_filter(inputSignalToFreqAnalysis,\\\n",
    "                                highFreqBand,reducedSamplingRate)\n",
    "\n",
    "hilbertTransformedSig = hilbert(inputSignalToFreqAnalysis)\n",
    "ampTransformedSig = np.abs(hilbertTransformedSig)\n",
    "\n",
    "for alertMovementEpochCounter in range(len(alertChoosedEpochsStarts)):\n",
    "    \n",
    "    movementTime = framesStartSample[alertChoosedEpochsStarts[alertMovementEpochCounter]]/fs\n",
    "#     epochEndTime = framesStartSample[alertChoosedEpochsEnds[alertMovementEpochCounter]]/fs\n",
    "    \n",
    "    epochStartTime = movementTime - windowToShow/2\n",
    "    epochEndTime = movementTime + windowToShow/2\n",
    "    \n",
    "#     plt.figure()\n",
    "#     temporalPlot(inputSignalToFreqAnalysis,epochStartTime,epochEndTime,reducedSamplingRate,\\\n",
    "#                 figuresize=(20,4),figNo=alertMovementEpochCounter)\n",
    "    temporalPlot(ampTransformedSig,epochStartTime,epochEndTime,reducedSamplingRate,\\\n",
    "                figuresize=(20,4),figNo=alertMovementEpochCounter)\n",
    "    plt.axvline(movementTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### power spectrum between movement and non-movement periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:12:39.289894Z",
     "start_time": "2020-04-22T13:12:37.198485Z"
    }
   },
   "outputs": [],
   "source": [
    "timToExclude = 0 \n",
    "\n",
    "df = 2 #in Hz; spectrum resolution\n",
    "\n",
    "inputSignalToFreqAnalysis = dataMatrixReorderLowPassFiltered[L5channelNo]\n",
    "f_spectrumL5, motionSpectrumL5Abs, stillnessSpectrumL5Abs, motionTotalPowerL5, stillnessTotalPowerL5\\\n",
    "            = spectrumCompareAlertNonAlert(inputSignalToFreqAnalysis,\\\n",
    "        alertChoosedEpochsStarts, alertChoosedEpochsEnds,\\\n",
    "     nonAlertChoosedEpochsStarts, nonAlertChoosedEpochsEnds, framesStartSample,\\\n",
    "     timeToExclude = timToExclude, df = df, figTitle = 'Spectrum L5')\n",
    "\n",
    "inputSignalToFreqAnalysis = dataMatrixReorderLowPassFiltered[L4channelNo]\n",
    "f_spectrumL4, motionSpectrumL4Abs, stillnessSpectrumL4Abs, motionTotalPowerL4, stillnessTotalPowerL4\\\n",
    "            = spectrumCompareAlertNonAlert(inputSignalToFreqAnalysis,\\\n",
    "        alertChoosedEpochsStarts, alertChoosedEpochsEnds,\\\n",
    "     nonAlertChoosedEpochsStarts, nonAlertChoosedEpochsEnds, framesStartSample,\\\n",
    "     timeToExclude = timToExclude, df = df, figTitle = 'Spectrum L4')\n",
    "\n",
    "inputSignalToFreqAnalysis = dataMatrixReorderLowPassFiltered[L23channelNo]\n",
    "f_spectrumL23, motionSpectrumL23Abs, stillnessSpectrumL23Abs, motionTotalPowerL23, stillnessTotalPowerL23\\\n",
    "            = spectrumCompareAlertNonAlert (inputSignalToFreqAnalysis,\\\n",
    "        alertChoosedEpochsStarts, alertChoosedEpochsEnds,\\\n",
    "     nonAlertChoosedEpochsStarts, nonAlertChoosedEpochsEnds, framesStartSample,\\\n",
    "     timeToExclude = timToExclude, df = df, figTitle = 'Spectrum L2/3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare the bands between motion and stillness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total  gamma Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:12:51.927035Z",
     "start_time": "2020-04-22T13:12:51.805391Z"
    }
   },
   "outputs": [],
   "source": [
    "lowBand = 30\n",
    "highBand = 70\n",
    "\n",
    "motionStillnessPowerCompare(motionSpectrumL5Abs, stillnessSpectrumL5Abs, lowBand, highBand,\\\n",
    "                                df, figTitle='Total gamma power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total 0-10 Hz Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:12:54.496051Z",
     "start_time": "2020-04-22T13:12:54.373373Z"
    }
   },
   "outputs": [],
   "source": [
    "lowBand = 0\n",
    "highBand = 10\n",
    "\n",
    "motionStillnessPowerCompare(motionSpectrumL5Abs, stillnessSpectrumL5Abs, lowBand, highBand,\\\n",
    "                                df, figTitle='Total 0-10Hz power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative gamma power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:13:03.739809Z",
     "start_time": "2020-04-22T13:13:03.621098Z"
    }
   },
   "outputs": [],
   "source": [
    "lowBand = 30\n",
    "highBand = 70\n",
    "\n",
    "relativeMotionPower = np.array([motionSpectrumL5Abs[epochCounter]/motionTotalPowerL5[epochCounter]\\\n",
    "                              for epochCounter in range(len(motionSpectrumL5Abs))])\n",
    "\n",
    "relativeStillnessPower = np.array([stillnessSpectrumL5Abs[epochCounter]/stillnessTotalPowerL5[epochCounter]\\\n",
    "                              for epochCounter in range(len(stillnessSpectrumL5Abs))])\n",
    "\n",
    "motionStillnessPowerCompare(relativeMotionPower,\\\n",
    "                            relativeStillnessPower, lowBand, highBand,\\\n",
    "                                df, figTitle='Rel gamma power',relPower=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative 0-10Hz power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:13:12.154678Z",
     "start_time": "2020-04-22T13:13:12.032972Z"
    }
   },
   "outputs": [],
   "source": [
    "lowBand = 0\n",
    "highBand = 10\n",
    "\n",
    "relativeMotionPower = np.array([motionSpectrumL5Abs[epochCounter]/motionTotalPowerL5[epochCounter]\\\n",
    "                              for epochCounter in range(len(motionSpectrumL5Abs))])\n",
    "\n",
    "relativeStillnessPower = np.array([stillnessSpectrumL5Abs[epochCounter]/stillnessTotalPowerL5[epochCounter]\\\n",
    "                              for epochCounter in range(len(stillnessSpectrumL5Abs))])\n",
    "\n",
    "motionStillnessPowerCompare(relativeMotionPower,\\\n",
    "                            relativeStillnessPower, lowBand, highBand,\\\n",
    "                                df, figTitle='Rel 0-10Hz power',relPower=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gamma power relative to the power in 0-10Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:13:23.264477Z",
     "start_time": "2020-04-22T13:13:23.149783Z"
    }
   },
   "outputs": [],
   "source": [
    "motionStillnessPowerCompareGammaAndLowFreq(motionSpectrumL5Abs, stillnessSpectrumL5Abs\\\n",
    "                                           ,df,figTitle='gamma/(0-10Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### changes in spont FR with facial movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:19:53.099149Z",
     "start_time": "2020-04-23T14:19:50.764968Z"
    }
   },
   "outputs": [],
   "source": [
    "motionSpontFR, stillnessSpontFR, motionSpontDur, stillnessSpontDur = \\\n",
    "spontFR_CompareAlertAndNonAlert(spikesSample, spikeClusters, spikeClustersToPlot,\\\n",
    "     alertChoosedEpochsStarts, alertChoosedEpochsEnds,\\\n",
    "     nonAlertChoosedEpochsStarts, nonAlertChoosedEpochsEnds, framesStartSample,\\\n",
    "     timeToExclude = 0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([1,2],np.array([motionSpontFR,stillnessSpontFR]),'o-',c='grey')\n",
    "plt.xticks([1,2],(['Motion','Stillness']),fontsize=12)\n",
    "plt.title('FR change with facial movement')\n",
    "plt.ylabel('firing rate (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:20:04.390800Z",
     "start_time": "2020-04-23T14:20:04.238203Z"
    }
   },
   "outputs": [],
   "source": [
    "stateFR_changeIndex = (motionSpontFR - stillnessSpontFR)/(motionSpontFR + stillnessSpontFR)\n",
    "pvalFRStateChange = stats.ttest_1samp(stateFR_changeIndex,0)[1]\n",
    "plt.hist(stateFR_changeIndex)\n",
    "plt.title('FR change index')\n",
    "plt.text(0.25,0.8,'p=%(number)0.3f'%{'number':pvalFRStateChange})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spike-triggering firing pattern during the spon activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:22:38.212894Z",
     "start_time": "2020-04-29T21:21:54.665191Z"
    }
   },
   "outputs": [],
   "source": [
    "# start and end of the part that is used to calculate the relative spiking of the pair of neurons\n",
    "sessionStart = 0\n",
    "sessionEnd = spontEndTime\n",
    "\n",
    "peakCrossCorrsAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "delaySpikingAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "triggeredSpikeTimesAllPairs = []\n",
    "smoothedCrossCorrsAllPairs = []\n",
    "ks_PvalAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "\n",
    "# getting the crosscorr pattern for all pair of neurons (calculation on haf of pairs: when the order of \n",
    "# neurons changes the peak value is the same and the delay is reversed relative to zero)\n",
    "for clusterCounter1 in range(len(spikeClustersToPlot)-1):\n",
    "    for clusterCounter2 in range(clusterCounter1+1,len(spikeClustersToPlot)):\n",
    "        clusterNo1 = spikeClustersToPlot[clusterCounter1]\n",
    "        clusterNo2 = spikeClustersToPlot[clusterCounter2]\n",
    "\n",
    "        # extract the spike time of the two neurons\n",
    "        spikeTimesNeuron1 = spikeTime[np.where(spikeClusters==clusterNo1)].squeeze()*1e3\n",
    "        spikeTimesNeuron2 = spikeTime[np.where(spikeClusters==clusterNo2)].squeeze()*1e3\n",
    "        \n",
    "        plt.figure()\n",
    "        \n",
    "        triggeredSpikeTimes, smoothedCrossCorr, peakCrossCorrsAllPairs[clusterCounter1][clusterCounter2], \\\n",
    "                    delaySpikingAllPairs[clusterCounter1][clusterCounter2],\\\n",
    "                    ks_PvalAllPairs[clusterCounter1][clusterCounter2] = \\\n",
    "                        spikeTriggeredFR(spikeTimesNeuron1,spikeTimesNeuron2,sessionStart,sessionEnd,\\\n",
    "                            preWindowLen = 100,postWindowLen = 100,figureShow=1)\n",
    "        \n",
    "        plt.title('CrossCorr Pattern Cluster %(number1)d and Cluster %(number2)d' \\\n",
    "                  %{'number1':clusterNo1,'number2':clusterNo2})\n",
    "\n",
    "        peakCrossCorrsAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                            peakCrossCorrsAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        ks_PvalAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                            ks_PvalAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        delaySpikingAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                            delaySpikingAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        triggeredSpikeTimesAllPairs.append(triggeredSpikeTimes)\n",
    "        smoothedCrossCorrsAllPairs.append(smoothedCrossCorr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross corrs movement vs stillness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:42:10.776137Z",
     "start_time": "2020-04-29T19:42:06.749874Z"
    }
   },
   "outputs": [],
   "source": [
    "peakCrossCorrsAlertAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "delaySpikingAlertAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "ks_Pval_AlertAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "triggeredSpikeTimesAlertAllPairs = []\n",
    "smoothedCrossCorrsAlertAllPairs = []\n",
    "\n",
    "peakCrossCorrsNonAlertAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "delaySpikingNonAlertAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "ks_Pval_NonAlertAllPairs = np.zeros([len(spikeClustersToPlot),len(spikeClustersToPlot)])\n",
    "triggeredSpikeTimesNonAlertAllPairs = []\n",
    "smoothedCrossCorrsNonAlertAllPairs = []\n",
    "\n",
    "for clusterCounter1 in range(len(spikeClustersToPlot)-1):\n",
    "    for clusterCounter2 in range(clusterCounter1+1,len(spikeClustersToPlot)):\n",
    "        clusterNo1 = spikeClustersToPlot[clusterCounter1]\n",
    "        clusterNo2 = spikeClustersToPlot[clusterCounter2]\n",
    "\n",
    "        # extract the spike time of the two neurons\n",
    "        spikeTimesNeuron1 = spikeTime[np.where(spikeClusters==clusterNo1)].squeeze()*1e3\n",
    "        spikeTimesNeuron2 = spikeTime[np.where(spikeClusters==clusterNo2)].squeeze()*1e3\n",
    "        \n",
    "        plt.figure()\n",
    "        \n",
    "        alertTriggeredSpikes, nonAlertTriggeredSpikes, \\\n",
    "        smoothedCrossCorrAlert, smoothedCrossCorrNonAlert, \\\n",
    "        peakCrossCorrsAlertAllPairs[clusterCounter1][clusterCounter2], \\\n",
    "        peakCrossCorrsNonAlertAllPairs[clusterCounter1][clusterCounter2], \\\n",
    "        delaySpikingAlertAllPairs[clusterCounter1][clusterCounter2], \\\n",
    "        delaySpikingNonAlertAllPairs[clusterCounter1][clusterCounter2], \\\n",
    "        ks_Pval_AlertAllPairs[clusterCounter1][clusterCounter2], \\\n",
    "        ks_Pval_NonAlertAllPairs[clusterCounter1][clusterCounter2] = \\\n",
    "                            spikeTriggeredFR_alertNonAlert(spikeTimesNeuron1,spikeTimesNeuron2,\\\n",
    "                            alertChoosedEpochsStarts, alertChoosedEpochsEnds,\\\n",
    "                            nonAlertChoosedEpochsStarts, nonAlertChoosedEpochsEnds, framesStartSample,\\\n",
    "                            preWindowLen = 100,postWindowLen = 100, timeToExclude = 0, fs = fs,\\\n",
    "                                figureShow =0)\n",
    "        \n",
    "        plt.title('CrossCorr Pattern Cluster %(number1)d and Cluster %(number2)d' \\\n",
    "                  %{'number1':clusterNo1,'number2':clusterNo2})\n",
    "        \n",
    "        \n",
    "        peakCrossCorrsAlertAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                                peakCrossCorrsAlertAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        peakCrossCorrsNonAlertAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                                peakCrossCorrsNonAlertAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        delaySpikingAlertAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                                delaySpikingAlertAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        delaySpikingNonAlertAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                                delaySpikingNonAlertAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        ks_Pval_NonAlertAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                                ks_Pval_NonAlertAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        ks_Pval_AlertAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "                                ks_Pval_AlertAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "        triggeredSpikeTimesAlertAllPairs.append(alertTriggeredSpikes)\n",
    "        triggeredSpikeTimesNonAlertAllPairs.append(nonAlertTriggeredSpikes)\n",
    "        \n",
    "        smoothedCrossCorrsAlertAllPairs.append(smoothedCrossCorrAlert)\n",
    "        smoothedCrossCorrsNonAlertAllPairs.append(smoothedCrossCorrNonAlert)\n",
    "\n",
    "#         peakCrossCorrsAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "#                             peakCrossCorrsAllPairs[clusterCounter1][clusterCounter2]\n",
    "        \n",
    "#         delaySpikingAllPairs[clusterCounter2][clusterCounter1] = \\\n",
    "#                             delaySpikingAllPairs[clusterCounter1][clusterCounter2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variables to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:33:47.099171Z",
     "start_time": "2020-04-30T19:33:46.968913Z"
    }
   },
   "outputs": [],
   "source": [
    "# 0 waveshapes\n",
    "# 1 spikeWidth\n",
    "# 2 spont FRs\n",
    "# 3 clusterChannel\n",
    "# 4 spike-triggered pupil area\n",
    "# 5 responsiveness \n",
    "# 6 baselineCorrectedResponse\n",
    "# 7 OSI\n",
    "# 8 Alert OSI\n",
    "# 9 nonAlert OSI\n",
    "# 10 relative response Change By Arousal\n",
    "# 11 basline change by arousal\n",
    "# 12 evoked-response change by arousal\n",
    "# 13 best direction response change by arousal\n",
    "# 14 noise correlation alert\n",
    "# 15 noise correlation non-alert\n",
    "# 16 normalized high freq power on all channels\n",
    "# 17 high freq power on all channels\n",
    "# 18 power sepctrum L5\n",
    "# 19 power spectrum L4\n",
    "# 20 power spectrum L23\n",
    "# 21 frequency vector\n",
    "# 22 power spectrum alert L5\n",
    "# 23 power spectrum non alert L5\n",
    "# 24 power spectrum alert L4\n",
    "# 25 power spectrum non alert L4\n",
    "# 26 power spectrum alert L23\n",
    "# 27 power spectrum non alert L23\n",
    "# 28 alert spont FR (facial movement periods)\n",
    "# 29 non-alert spont FR (based on the facial movement)\n",
    "# 30 L5 estimated channel\n",
    "# 31 vectors of triggered spike times (all pairs of neurons)\n",
    "# 32 matrix of the peak values of the smoothed cross correlograms for all pairs (distance of conditioned PDF from chance level)\n",
    "# 33 matrix of delay of cross-correlograms for all pairs (argmax of the conditioned PDF)\n",
    "# 34 smoothed cross-corrs for all pairs\n",
    "# 35 triggered spike times during alert periods for all pairs (facial movement for the alertness)\n",
    "# 36 peak of cross corrs during alertness\n",
    "# 37 delay of cross corres for alert periods for all pairs\n",
    "# 38 smoothed cross-corrs for alert periods for all pairs\n",
    "# 39 triggered spike times during non-alert periods for all pairs (facial movement for the alertness)\n",
    "# 40 peak of cross corrs during non-alertness\n",
    "# 41 delay of cross corres for non-alert periods for all pairs\n",
    "# 42 smoothed cross-corrs for non-alert periods for all pairs\n",
    "# 43 ks-test pvalue for all pairs (cross-corr patterns against the uniform distribution)\n",
    "# 44 spike-triggered facial movement\n",
    "# 45 ks-test pvalue for all pairs during alert period\n",
    "# 46 ks-test pvalue for all pairs during nonAlert period\n",
    "\n",
    "animalName = dataFileBaseFolder[len(dataFileBaseFolder) - dataFileBaseFolder[::-1].find('/'):\\\n",
    "                   len(dataFileBaseFolder) - 13]\n",
    "\n",
    "savingAdd = 'Y://Ehsan-temp//Claire-Ehsan_Share//DataToMerge//'\n",
    "\n",
    "variableToExportToMerge = [spikeShapesFiltered, spikeWidthAll, spontFRs, clusterChannel,\\\n",
    "        allSpikeTriggeredPupil, allClustersResponsiveness, \\\n",
    "        allClustersBaselineCorrectedResponse, allOSI, OSI_Alert, OSI_nonAlert,\\\n",
    "        allClustersNormalizedArousalResponseChange, allClustersNormalizedArousalBaselineChange,\\\n",
    "        evokedResponseChangeByArousa, bestDirectionRelResponseChangeByArousal, noiseCorrAlert, \\\n",
    "        noiseCorrNonAlert, allChannelsNormHighFreqPower, allChannelsHighFreqPower, powerSpectrumL5,\\\n",
    "        powerSpectrumL4, powerSpectrumL23, f_powerSpectrum, motionSpectrumL5Abs, stillnessSpectrumL5Abs,\\\n",
    "        motionSpectrumL4Abs, stillnessSpectrumL4Abs, motionSpectrumL23Abs, stillnessSpectrumL23Abs,\\\n",
    "        motionSpontFR, stillnessSpontFR, L5channelNo, triggeredSpikeTimesAllPairs, peakCrossCorrsAllPairs,\\\n",
    "        delaySpikingAllPairs, smoothedCrossCorrsAllPairs, triggeredSpikeTimesAlertAllPairs, \\\n",
    "        peakCrossCorrsAlertAllPairs, delaySpikingAlertAllPairs, smoothedCrossCorrsAlertAllPairs,\\\n",
    "        triggeredSpikeTimesNonAlertAllPairs, peakCrossCorrsNonAlertAllPairs, delaySpikingNonAlertAllPairs,\\\n",
    "        smoothedCrossCorrsNonAlertAllPairs, ks_PvalAllPairs, allSpikeTriggeredFacialMovement,\\\n",
    "        ks_Pval_AlertAllPairs,ks_Pval_NonAlertAllPairs]\n",
    "\n",
    "import pickle\n",
    "pickle.dump(variableToExportToMerge, open(savingAdd+animalName+'.pkl', \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-11T19:12:42.566Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.savemat('test.mat',{'i':i,'m':m,'rule':rule})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraDataValid = True\n",
    "\n",
    "if not(cameraDataValid):\n",
    "    allOSI = []\n",
    "    OSI_Alert = []\n",
    "    OSI_nonAlert = []\n",
    "    allClustersNormalizedArousalResponseChange = []\n",
    "    allClustersNormalizedArousalBaselineChange = []\n",
    "    evokedResponseChangeByArousa = []\n",
    "    bestDirectionRelResponseChangeByArousal = []\n",
    "    noiseCorrAlert = []\n",
    "    noiseCorrNonAlert = []\n",
    "    motionSpectrumL5Abs = []\n",
    "    stillnessSpectrumL5Abs = []\n",
    "    motionSpectrumL4Abs = []\n",
    "    stillnessSpectrumL4Abs = []\n",
    "    motionSpectrumL23Abs = []\n",
    "    stillnessSpectrumL23Abs = []\n",
    "    motionSpontFR = []\n",
    "    stillnessSpontFR = []\n",
    "    triggeredSpikeTimesAlertAllPairs = []\n",
    "    peakCrossCorrsAlertAllPairs = []\n",
    "    delaySpikingAlertAllPairs = []\n",
    "    smoothedCrossCorrsAlertAllPairs = []\n",
    "    triggeredSpikeTimesNonAlertAllPairs = []\n",
    "    peakCrossCorrsNonAlertAllPairs = []\n",
    "    delaySpikingNonAlertAllPairs = []\n",
    "    smoothedCrossCorrsNonAlertAllPairs = []\n",
    "    allSpikeTriggeredFacialMovement = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
